\chapter{Setup for high resolution imaging}

In order to understand the nature of atoms in more detail, experiments are conducted where they are trapped and cooled. Under these circumstances, interactions between atoms can be tuned using Feshbach resonances. This allows to build up for example Bose-Einstein condensates (BEC) or Cooper pairs. The complete setup has been explained in more detail before \cite{Repp2013}. The following sections will focus on the imaging in order to extract these attributes and the measures it takes to reduce noise sources on the camera.

\section{Experimental requirements}
In this double species experiment, fermionic $^6$Li and bosonic $^{133}$Cs are trapped and cooled inside a vacuum chamber. The atoms are emitted from an oven into a Zeeman slower, which transfers them into a magneto-optical trap. The MOT will further cool the atoms up to the doppler limit (~\SI{140}{\micro\kelvin}). To reach lower temperatures, the atoms will be trapped inside an optical dipole trap. Forced evaporative cooling will release the fastest atoms, until temperatures of a few nano Kelvin are reached.

\pltCustom{
	\vspace{1em}
	\begin{center}
		\includegraphics[width=1\textwidth]{drafts/imaging_path.pdf}
	\end{center}
	
	\begin{textblock}{2}(0.2,-2.65)
		\textbf{a.}
	\end{textblock}
	\begin{textblock}{2}(5.7,-2.65)
		\textbf{b.}
	\end{textblock}
}{imaging_path}{Imaging path}{The camera is mounted above the vacuum chamber as visible in \textbf{a.} (gravity would be in negative $z$ direction). The image of the atoms is collimated with the first lens and passing the optics in \textbf{b.}, until it is refocused in the chip on the camera.}

In order to image the atoms, an imaging beam is pointing along the $z$-axis according to \refFig{imaging_path}.
An achromatic doublett \todo{get back to stephan. is this correct?} lens focuses the imaging beam onto the CCD camera, which is located on top of the vacuum chamber.

In order to measure even at low atom numbers ($n=1000$), the setup was refined allowing for high resolutions. The first lens, which collimates the image of the atoms has a low focal length (f=\todo{focal length}).
The image is refocused into the camera by the second lens. Since the imaging uses two separate frequencies to image both Lithium and Caesium, the chromatic shift introduced by the lenses will result in two different focal points for the images. This can be compensated by a high focal length, which therefore allows to have the camera in the Rayleigh range of both laser beams.

This setup then allows to image for example Bose-Einstein gases, polarized Fermi gases or superfluids with high accuracy.


\section{Camera for double species imaging}
\label{ch:camera}
The camera used in order to find atoms, the Andor iKon M, is a charge-coupled device (CCD), which offers an improvement to the old setup. Using this camera, noise sources such as Readout noise and Dark noise can be reduced, which are explained in the following sections.

\subsection{Basics of CCD cameras}
\label{ch:ccd_basics}

A camera operates by means of converting photons first into electrons then into voltage, which is finally read out as data\cite{ccdoperationUrl}\cite{guppy38Bsheet}. Each conversion process can add noise to the final image, which needs to be minimized in order to acquire accurate data. The most common noise sources are covered in \refCh{camera}.

The photons are collected on an array of semiconductor photo diodes, called the pixels, where ideally the spacing between the pixels is zero to gain maximum accuracy. The resolution is then dependent on the pixel size, which is for scientific cameras usually between \SI{10}{\micro\meter} and \SI{20}{\micro\meter} per pixel. Bigger pixels means higher photon sensitivity but usually lower resolution.

\draft{ccd_shifts}{Schematic design of a CCD array and its readout}{
	The pixels are arranged in the pixel array. During readout they are shifted into the readout register and then to the side into the analog to digital converter
}

To create a digital image, the charge from the pixels have to be shifted one-by-one into the analog digital converter (ADC). This is done, by vertically shifting them into the readout register and then horizontal into the ADC, where the charges are multiplied and converted to digital data.

The shifting is done by storing the charges after collecting them, where each storage can be seen as an electronic potential well. In order to shift the charges and prevent overlapping, three spatially separated regions with potentials $U_1$, $U_2$ and $U_3$ are required. \refFig{charge_shift} indicates the systematics behind the shifting.

\draft{charge_shift}{Shifting charges in a CCD detector}{
	To shift charges from Pixel A to Pixel B, the three potentials at the regions $U_1$, $U_2$ and $U_3$ in each pixel have to be set accordingly to allow the charge flow without overlapping each other. Each row represents a single step.
}

Moving electrons to the next region is a three-step process. The charges are first only present in the region $U_2$, while the potentials $U_1$ and $U_3$ are kept high. They are then distributed across $U_2$ and $U_3$ by setting them both low. At last $U_2$ will be set high such that the charge is now fully in $U_3$. This is repeated until the charge has been finally shifted from pixel A to B, which in total takes seven steps.


\subsection{Comparison with the present setup}
\label{sec:comparison}
For the imaging of small atomic clouds, it is very important to have cameras with optimal noise and maximal readout speed. The new setup improves on both attributes. The dark noise can be significantly reduced by cooling the chip down to more than \SI{70}{\degreeCelsius}. A new readout mode, called fast kinetics, makes it possible to acquire all images before reading out. This significantly improves the speed at which images can be taken.

The readout speed is highly important in our setup. Since absorption imaging is the technique of choice to measure atom attributes, three images need to be taken each sequence, being the absorption, division and background image.
The old setup used a Guppy-38B \cite{Repp2013} camera, which has a frame rate of 30fps. This meant the acquisition was finished after \SI{100}{\milli\second}. The Andor camera, on the other hand, can take images quickly without the need to read out in-between. At the fastest shift speed, the acquisition is finished after \SI{1.632}{\milli\second}, improving the speed by a factor of more than $60$.

The quantum efficiency is explained in \refCh{quantumeff} and is also highly important, as it describes how many photons are detected on a camera and is directly connected to the sensitivity. A higher quantum efficiency therefore means better results. They compare as $QE_{Li} = 79\%, QE_{Cs} = 77.3\%$ for the Andor and $QE_{Li} = 35\%, QE_{Cs} = 10\%$ for the Guppy camera, therefore the sensitivity of the new camera is significantly higher.

When comparing the resolution, the chip size also has to be considered. Since higher resolutions seem to be preferable at first, it also means that for the same pixel sizes, the photon sensitivities will decrease. The pixel sizes compare to \SI{8.4}{\micro\meter} $*$ \SI{9.8}{\micro\meter} to \SI{13}{\micro\meter} * \SI{13}{\micro\meter} from the old versus the new setup respectively, while the resolutions are \SI{768x492}{} and \SI{1024x1024}{} making a larger magnification now possible.

The Guppy camera is a lot smaller than the Andor iKon M (\SI{48.2x30x30}{\milli\meter} vs \SI{204.2x105x107}{\milli\meter}), therefore making an implementation on a full experimental table easier. To implement such a complicated camera system that the Andor is, a lot of preparation was made in the thesis of Carmen Renner \cite{Renner2014}.

Nevertheless, despite its size, the new camera offers the ability to image both Lithium and Caesium species at once, while two Guppy cameras were needed beforehand, which also meant placing them on different imaging axes.

\subsection{Dark current}
%http://www.kip.uni-heidelberg.de/matterwaveoptics/publications/theses/diplom_ottenstein.pdf
%http://www.mpia.de/AO/INSTRUMENTS/FPRAKT/4_F36_CCDscript2011.pdf
A common noise source that is apparent in all CCD cameras, is the so-called dark current \cite{Ottenstein2006} . It originates from the thermal excitation of electrons in individual pixels. Since they are made of semiconductors, once in a while, an electron can pass the potential between valence and conduction band simply due to their thermal energy. Thus, excess electrons accumulate, that contribute to the background signal and introduce additional noise\cite{FP362011}.

The dark current has a strong temperature dependence
\begin{equation}
\label{eq:darkcurrent}
I_{dark}(T) \propto T^{\frac{3}{2}} \mathrm{exp}(-E_g/2k_BT),
\end{equation}
while $E_g$ is the band gap, that separates the valence from the conduction band in the semiconductor, $T$ the temperature and $k_B$ the Boltzmann constant.
Therefore in order to reduce dark current noise, the temperature of the chip can be reduced, which decreases the thermal energy of the electrons.

This has been measured and verified in \refFig{electrpp}, using the built-in peltier element in the Andor camera to control the temperature of the CCD chip. For a long exposure time, dark current accumulates on all pixels. The counts are measured for several temperature settings and the counts $C$ are converted to electrons per pixel per second ($I_i$)\cite{Ottenstein2006} for each pixel $i$ as
\begin{equation}
I_{i} = \frac{C}{G t_{exp}}
\end{equation}

\plt[true]{electrpp}{Dark noise accumulation on the chip}{
	For a long exposure time of \SI{100}{\second}, the dark current was measured for several temperatures. Gain in this measurement was minimal ($0.215$\cite{Renner2014}). Equation \ref{eq:darkcurrent} was fitted, leaving the amplitude $A$ and band gap $E_g$ free, which resulted in $A=1.1*10^8\, \SI{}{\watt\per\meter\per\kelvin}$ and $E_g=\SI{0.96}{\electronvolt}$.
}

with the Gain $G$ of the camera, and the exposure time $t_{exp}$. The readout time of the pixels can be neglected, as they are significantly lower than the exposure time (see \refCh{fast_kin}).
The data should then follow the theory in \refEq{darkcurrent}, although deviations are visible in the low temperature regime, which result from the fan not being able to divert the heat from the chip.

As it is important to minimize the noise source, the chip is cooled as low as possible. This will reduce the possibility of thermal electrons creating counts in the detector, so that even at fewer atom numbers, they are still distinguishable from the noise.

\subsection{Readout noise}
As described in \refCh{ccd_basics}, pixels are shifted in order to be read out by the ADC. Moving charges from pixel to pixel causes noise that accumulates over each iteration. Together with the noise which the ADC introduces, this is then called the readout noise. The shifting noise together with the dark noise is visible as a gradient (\todo{figure with shift gradient}) since each shift adds new charges due to excitations in the semiconductors. In order to characterize this, one can take the variance of the image, which should be zero for no noise.

In \refFig{hvspeed} it has been shown, that slow readout speeds reduces the noise, although the vertical shift speeds do not seem to influence the noise at all. The measurement was carried out by taking images at low exposure time and low temperature, so that the main noise source would be the readout and not the dark current. Therefore the variance in the plot shows the noise from readout which goes to zero as the horizontal speed is decreased.

The actual readout of the chip can be done at slow speeds, so that the noise from horizontally shifting is low. As the vertical shifts do not add significant noise, it can safely be set to fast speeds, which is also favorable, as $^6$Li and $^{133}$Cs are imaged back to back as fast as possible, so that the cloud dynamics are still approximately the same.

Shifting charges means increasing and decreasing potential wells, so that they can move from one into the other. If this is done fast enough (non-adiabatic), electrons in the pixel are more likely to get excited from the valence to the conduction band from the semiconductor, therefore adding noise. As a result from this, slower readout speeds are used in order to not add significantly more noise.

\plt{hvspeed}{Readout noise}{
	The pixels are shifted row-wise into the readout register, depending on the vertical shift speed ($v_{ss}$) and then moved pixel-by-pixel with the horizontal shift speed into the analog to digital converter. Since noise reduction is important, minimal horizontal shift speeds will be used, while the vertical shift speed does not seem to affect the variance. To make the readout the dominant noise source, temperature was set to \SI{-69}{\degreeCelsius} and exposure to \SI{10}{\milli\second}. The results have been received from taking the mean and variance of multiple sets of exposures.
}

\newpage
\subsection{Quantum efficiency}
\label{ch:quantumeff}
When selecting cameras for scientific imaging, one of the attributes to look out for is quantum efficiency (QE). Not all incoming photons are converted into electrons, which adds an uncertainty and additional noise to measurements. This is characterized by quantum efficiency, which is defined as the fraction of photons that are converted into electrons. A  QE of 100\% would mean, that every incident photon is converted into an electron on the chip. This can be put into equations as
\begin{equation}
QE = \frac{N_{detected}}{N_{total}},
\end{equation}
where $N_{detected}$ describes the number of detected photons and $N_{total}$ the number of photons that were sent from the laser beam.

The measurement of the quantum efficiency has been previously carried out by Carmen Renner \cite{Renner2014} in her diploma thesis. In order to do that, the detected photons can be rewritten according to \cite{Murmann2011}:
\begin{equation}
N_{total} = \frac{E_{beam}}{E_\gamma} = \frac{P t_{exp}}{E_\gamma}
\end{equation}
where the energy of all photons reaching the camera $E_{beam}$ is described with the power $P$ and exposure time $t_{exp}$. The photon energy $E_\gamma$ is calculated from $E_\gamma= h\nu$.

Now the quantum efficiency reads as
\begin{equation}
QE = \frac{h \nu N_{detected}}{P t_{exp}}.
\end{equation}

In order to find the QE, one would now measure the accumulated counts for several exposure times, since the frequency $\nu$ and the power $P$ are known. For the Andor camera used in our experiment, they have been measured as \SI{70.7}{\percent} for \SI{671}{\nano\meter} and \SI{69.9}{\percent} for \SI{852}{\nano\meter}.

This camera was especially chosen from the quantum efficiency, since it is important in our case, to be able to detect most photons from Lithium and Caesium absorption.

\section{Mechanical shutter}
\label{sec:shutter}

Due to the high quantum efficiency, the camera is very sensitive to stray light. Therefore it is necessary to cover the chip from stray light. A mechanical shutter which can be electronically controlled is therefore built in front of the light path, which prevents the camera from damage between measurements. The electronics were set up and the shutter characterized in order to find perfect timings, so that light only enters the chip, when a measurement is running.

\subsection{Electronic and mechanical setup}
\label{subsec:shutter_electronic}
\todo{cite andor manual somewhere}

The high QE of the Andor camera translates into a high sensitivity of the CCD chip to stray light. Therefore, in order to not unnecessarily illuminate the chip between measurements, a mechanical shutter was built into the optical path, which can also be seen in \refFig{imaging_path}. By opening the shutter shortly before the imaging sequence and closing it immediately afterwards, the stray light that is implying the CCD detector can be minimized.

The shutter has five fans, as seen in \todo{appendix image}, which are mechanically guided, such that they together perform a circular motion outwards. The circular motion is best achieved for narrow fans, therefore needing more in order to close the shutter properly.

The guides are connected to each other and can be pulled outwards with a mechanical switch, that can be manually pushed or pulled. To drive the shutter electronically, a magnetic coil and a magnet are used. When the coil receives a current, the magnet, which is connected to the switch will pull the guides, moving them outwards, therefore opening the shutter.

Although the coil can pull the magnet in, it cannot be pushed away. This is compensated using a spring, which is connected to the switch. This also means, that the current driving the coil needs to be high enough, to also work against the spring.

The most optimal case would be now to have fast opening and closing times, since again we want to prevent illumation between measurements. This can be achieved by testing several springs and to make the pull from the magnetic coils as fast as possible, which means increasing the current to drive it.

A custom circuit as outlined in \refFig{shutter_circuit_simplified} is used. In order to serve a high current to increase the pull from the magnetic coil on the magnet, a transistor is used which is controlled by a MOSFET driver. The complete circuit also contains a voltage regulator, so that the user does not need to know the input of the driver and can simply serve a high voltage to open the shutter ($V\in\left[2,8\right]\mathrm{V}$) and a low voltage ($V=\SI{0}{\volt}$) to close it.

\pltCustom{
	\begin{center}
		\includegraphics[width=1\textwidth]{drafts/shutter_circuit_simplified.pdf}
	\end{center}
}{shutter_circuit_simplified}{Electronic circuit to control the shutter}{
The first element in the circuit is the optocoupler which is used to decouple parts from the circuit in order to not create  loops, which would induce charges when the magnetic fields are on.
The remaining parts can be skipped, by setting the jumpers. The inverter will flip the sign on the voltage. The MOSFET driver is used in order to serve the correct voltage at the transistor's gate and to help during discharge, such that the MOSFET will not overheat. The transistor will finally serve a high current of \SI{2.5}{\ampere}, that is throughput to the shutter.
The jumpers in this figure are set as they are used in the experiment. The complete circuit can be found in \refAp{shutter_circuit}.
}

\newpage
\subsection{Dynamical properties}
The shutter operates by controlling a magnetic coil, which pulls a magnet. The magnet is reverted into its original position by a spring, closing the shutter. 
It was discussed before, in \refSubsec{shutter_electronic}, that more fans give a better approximation to a circular motion. Optimally, we would expect the shutter to open perfectly circular with linear velocity. Therefore, to optimize on this, one would look at opening and closing speeds, which should be minimal.

\label{subsec:shutter_dynamical}
\pltCustom{
	\begin{center}
		\includegraphics[width=0.8\textwidth]{drafts/shutter_experiment.pdf}
	\end{center}
	
	\begin{textblock}{2}(0.8,-2.55)
		\textbf{a.}
	\end{textblock}
	\begin{textblock}{2}(6.3,-2.55)
		\textbf{b.}
	\end{textblock}
}{shutter_experiment}{Probing the shutter for dynamics}{The shutter is proped at several positions using a laser. The offset in y direction was varied to find opening and closing times as a function of their offset.}

To find the actual dynamics of the shutter, an experiment was set up. The shutter was probed at several positions, using a laser, to find the opening time. An example of one of many measurements is shown in \refFig{shutterDiodeSignal}. The laser beam has a gaussian intensity distribution, which results in a error function on the photodiode as only partial intensiy is received from the diode, when the shutter is still blocking parts of the beam.

The points have been found by pointing a laser beam at a photodiode, which was blocked by the shutter. Since the laser has a finite radius, there is a transition in the signal from the minimum to the maximum, which is due to the approximately linear opening velocity of the shutter and the gaussian intensity distribution of the laser beam.

\plt{shutterDiodeSignal}{
	Shutter characterization}{The dynamics of the shutter were measured using a laser beam with a variable horizontal offset, which is fixed in this plot, and a photo diode measuring the laser intensity. In this figure, the offset is \SI{9.3}{\milli\meter} from the center. An error function was fitted yielding the time until the shutter opens. The opening time was hereby defined, where the error function has its mean value, in this example being \SI{5.2}{\volt}.
}

In order to find the opening and closing times of the shutter as seen in \refFig{shutterOpen}a., the offset from the centre of the shutter was varied. For larger offsets, the time from the initial trigger until a signal in the photodiode was received takes longer when the shutter is opening, while it takes shorter when it is closing.
In \refFig{shutterOpen}b. the speed is not perfectly linear. The deviations close to the centre originate from the shape of the fans. As there are five fans, there is no mirror symmetry, so that opening to the left and right is different in the end.

These measurements will later be used to time the triggers in the measurement, so that the shutter can stay closed as long as possible. But in order to optimize it, there were two shutters at hand, and several springs to choose from, the combination of which were all tested until the timings for opening $t_{open}=\SI{0.12}{\second}$ and for closing $t_{closing}=\SI{0.14}{\second}$ were found.

\pltCustom{
	\begin{center}
		\input{plots/shutterOpen.pgf}
		\input{plots/shutterClose.pgf}
	\end{center}
}
{shutterOpen}{Sample dynamics}{
	The figure shows opening and closing time as well as the opening velocity for a strong spring. The spring closed the shutter quickly while it prevented it from opening fast.
	The velocity was measured by using the beam diameter as the distance the shutter needed to transverse. For each offset, a set of ~100 images were taken and the errors found as being the variance. It is noticeable, that the opening velocity on the right side is faster at first than on the left side. This is due to the structure of the shutter, as can be seen in [Appendix image of shutter].
	The overall opening speed on the other hand is not affected by this and seems to be linear with the offset.
}
\todo{appendix image}

It has been found that the opening time consists of actually three timings. The initial trigger signal runs through the electronics, until it is sent to the shutter coil. The coil then has a delay, until it starts pulling the magnet. The opening time is then found by also adding the time until the fans are fully open. This is also shown in \refFig{shutterSignals}.

\draft{shutterSignals}{Shutter opening timings}{In the figure, the four signals show the timings until the shutter is open. The blue signal is the trigger that is sent from the user to start the opening sequence. The electronics add some minor delay, which is about a few nanoseconds until they send out the green trigger. After a certain delay time, which is most likely due to the coil needing to accumulate charge first, the red signal indicates when the shutter starts to open at the centre. The opening sequence is finished, when the shutter is fully open, which is shown by the turquoise line.}

\newpage
\section{Mask for the CCD sensor}
One of the key features of the Andor iKon M is the fast kinetics readout mode. This allows for fast acquisition, which is important when imaging multiple species. Using this acquisition mode, we are able to take images \SI{500}{\micro\second} apart from each other, so that it is possible to take consecutive images from the same cloud before it is too dilute.
The acquisition mode is explained in these sections as well as the diffractions introduced by a slit, which is needed to mask parts of the chip.

\subsection{Fast kinetics mode}
\label{ch:fast_kin}
The fast kinetics mode allows the image acquisition timings to be only dependent on the vertical shift speed, reducing the acquisition time significantly. In this mode, only a portion of the CCD is illuminated, while the dark parts of the chip will be used as a storage. This means, that as soon as an image is taken, the illuminated pixels are shifted vertically behind a mask, such that no photons can reach them any more. When the chip is full or the user has finished their acquisition, the readout process is started.

As explained earlier in \refCh{ccd_basics}, the readout consists of first shifting a row into the readout register and then horizontally shifting them into the ADC. This is a very time consuming process, since the total readout time is described by
\begin{equation}
t_{ij} = i v_{ss} + (i-1) j_{max} h_{ss}+j h_{ss},
\end{equation}
where $v_{ss}$ and $h_{ss}$ indicate the vertical and horizontal shift speed respectively.
With this equation, the readout time until a pixel with the coordinates $i$ and $j$ is shifted into the readout register can be calculated. The readout of all pixels beforehand is also taken into account by $j_{max}$ which is the width of the chip in pixels (1024 for the iKon M camera).
As can be seen, in the terms of the horizontal speed, the position of the last pixel in a row has a quadratic dependency. This is the dominant contribution to the readout time, which is necessary to shift the pixels into the ADC. At this point, the speed should not matter too much any more, because the experiment is already finished and the pixels are not illuminated any more.

\pltCustom{
	\begin{center}
		\begin{overpic}[width=0.5\textwidth]{drafts/fast_kinetics.pdf}
			\put (-6,92) {\textbf{a.}}
			\put (41,92) {\textbf{b.}}
			\put (58,92) {\textbf{c.}}
			\put (5,44) {\textbf{d.}}
			\put (27,44) {\textbf{e.}}
			\put (49,44) {\textbf{f.}}
			\put (69,44) {\textbf{g.}}
		\end{overpic}
	\end{center}
}{fast_kinetics}{Schematics of imaging in the fast kinetics mode}{
\textbf{a.}\enskip Laser photons excite electrons in pixels, creating the first absorption image.
\textbf{b.}\enskip The illuminated pixels are shifted down behind a cover, while the laser is shut off.
\textbf{c.}\enskip The second absorption image is taken without affecting the last measurement.
\textbf{d.}\enskip Both images are shifted down before starting the readout process, to not falsify the data with stray light.
\textbf{e.}\enskip The readout process starts, the first row is shifted into the readout register.
\textbf{f./g.}\enskip The first pixels are shifted into the ADC. It is repeated until the complete chip has been read out.
}

To set up the fast kinetics mode, there are several parameters that need to be set in advance.
\begin{itemize}
	\item \textbf{Series length}.\, The number of images acquired before the readout phase is initiated.
	\item \textbf{Exposed rows}.\, The height of an image in the fast kinetic series.
	\item \textbf{Offset from bottom}.\, Number of rows from the bottom of the chip, which are used as a temporary storage for the illuminated pixels.
\end{itemize}

It can be easily seen that the parameters are limited by the height of the CCD in pixels:
%The CCD has a pixel height of \SI{1024}{\px}, such that the condition
\begin{equation}
\mathbf{Exposed\,rows} + \mathbf{Offset\,from\,bottom} \leq \SI{1024}{px}
\end{equation}
and
\begin{equation}
\mathbf{Series\,length}*\mathbf{Exposed\,rows} \leq \mathbf{Offset\,from\,bottom}.
\end{equation}
Therefore, in our application, we chose to expose \SI{204}{\px} with an offset of \SI{820}{\px}, which gives a series length of $4$.
The pixels that are used as temporary storage of accumulated charge until the readout process begins need to be shielded from light. This is achieved with a slit in front of the camera that blocks part of the light beam implying on the CCD detector.

Since we will be imaging two atomic species, an absorption image for each species will be followed by two division images, as well as background images to subtract the noise.

\subsection{Frequency response of a slit}
\label{subsec:slit}

The slit is an optical element in the path, which will introduce diffraction --- an effect due to the wave nature of light.
\refFig{slit_sketch} sketches the systematics behind a plane wave approaching a slit.

\draft{slit_sketch}{Diffraction on a single slit}{A planar wave with the wavelength $\lambda$ approaches a slit with a width $a$, where the maxima of the wave are drawn as dashed lines. After the slit, Huygens principle is sketched as spherical waves, (purple and green), interfering with each other. The new wavefront is created where the waves cross each other and is as such visible on the screen to the right.}

The incoming planar wave can be described by the formula:
\begin{equation}
E(z) = E_0 e^{-ikz},
\end{equation}
where the wave is propagating in the $z$-direction with the wave number $k$ and an amplitude $E_0$.

It is known from Huygens principle, that each point from a planar wave can be seen as the origin of a spherical wave. The spherical waves will interfere with each other and because of the superposition principle a new wavefront will be built up.

The mathematical formalism of Huygens principle is simply the sum of all spherical waves, which for infinitely small distances is given as\cite{Steck2012}:
\begin{equation}
E(x,z) = E_0 C \int_{Slit} \frac{1}{r^2} \mathrm{exp}(-ikr)\mathrm{d}x'.
\end{equation}
Here, $r=\sqrt{(x-x')^2 + z^2}$ is the radius of a two dimensional wave, C is a normalization constant.
Taylor expansion of the radius for $z$ allows us, to substitute $r^2$ with $z^2$ and $r$ with $\frac{(x-x')^2}{2z} + z^2$, while also the approximation $(x-x') \ll z$ needs to be fulfilled. Therefore we get:
\begin{equation}
E(x,z) = E_0 e^{-ikz}\sqrt{\frac{ik}{2\pi z}}\int_{Slit} \mathrm{exp}\left( -\frac{ik}{2z}(x-x')^2\right) \mathrm{d}x'.
\end{equation}
The normalization was derived from the gaussian normal distribution $\mathrm{exp}( -\frac{ik}{2z}(x-x')^2)$. The integral will run over the slit size, with the origin in its middle and width $a$.
We want to also write the exponential as a function of $-\frac{i\pi t^2}{2}$, due to the definition of fresnel integrals. The substitution follows:
\begin{equation}
\frac{k}{2z}(x-x')^2 = \frac{\pi t^2}{2},
\end{equation}
\begin{equation}
\Rightarrow t = \sqrt{\frac{k}{z\pi}}(x-x'), \\
\end{equation}
\begin{equation}
\Rightarrow \mathrm{d}x' = -\mathrm{d}t \sqrt{\frac{z\pi}{k}},
\end{equation}
such that the field becomes
\begin{equation}
E(x,z) = -E_0 e^{-ikz}\sqrt{\frac{i}{2}}\int_{t(-a/2)}^{t(a/2)} \mathrm{exp}\left( -\frac{i\pi t^2}{2}\right) \mathrm{d}t.
\end{equation}
The fresnel integrals are defined by
\begin{equation}
C(x) = \int_0^x \mathrm{cos}\left(\frac{\pi t^2}{2}\right)\mathrm{d}t,
\end{equation}
\begin{equation}
S(x) = \int_0^x \mathrm{sin}\left(\frac{\pi t^2}{2}\right)\mathrm{d}t,
\end{equation}

so that in combination with Eulers equations and splitting up the integrals the equation for the electric field is:
\begin{equation}
E(x,z) = E_0 \sqrt{\frac{i}{2}} e^{-ikz} \left [ C(-a/2) - C(a/2) - iS(-a/2) + iS(a/2) \right ].
\end{equation}

In a real experiment, the light on a CCD chip is detected as intensity, which is given by
\begin{equation}
I(x,z) = \frac{2 \lvert E(x,z) \rvert ^2}{\epsilon_0 c} ,
\end{equation}
with the dielectric constant $\epsilon_0$ and the speed of light $c$.

To verify the theory, we set up a simple experiment with a collimated laser beam pointing at the CCD of the Andor camera, with a slit in between. Such behaviour was also observed in our measurements. \refFig{slit} shows the diffraction pattern that was recorded with the Andor camerea and a slit. A large, collimated beam was used to illuminate a slit in front of the CCD detector. Well resolved interference fringes can be observed behind the slit.

\pltCustom{
	\begin{center}
		\input{plots/slit.pgf}
		\input{plots/diffractionImage.pgf}
		%\includegraphics[width=0.4\textwidth,height=0.2\textheight]{plots/diffractionImage-img0.png}
	\end{center}
}
{slit}{Measuring diffraction on a slit}{
	In order to characterize the diffraction by the slit, the CCD detector was placed as close as possible. The parameters were measured using a ruler and yielded distance $d=\SI{10.9\pm0.5}{\milli\meter}$, opening $a=\SI{2.5\pm0.5}{\milli\meter}$. The wavelength was $\lambda =\SI{852}{\nano\meter}$ found from the laser specifications. The blue curve is the experimental data, while the red curve was fitted, leaving the distance and opening as free fitting parameters. They were found to be $d^\prime=\SI{11.0\pm0.3}{\milli\meter}$ and $a^\prime=\SI{2.470\pm0.013}{\milli\meter}$, which is in close agreement with the measured values.The residual deviation in the amplitude are caused by Gaussian intensity distribution of the laser beam used for illumination.
}

The experimental diffraction pattern matches the theory very well, since the deviations are in the expected regimes.
The function washes out as it approaches the centre of the chip. This is due to the nature of the pixels, which only have a finite size and the fact, that the frequencies of the oscillations are lower on the outer ends. All oscillations that fit into one pixel are averaged, therefore diffraction is not visible.

This result helps to minimize the diffraction on the chip and serves as a starting point in order to optimize this effect.

\subsection{Optimization of the masking setup}
\label{subsec:slit_optim}

An important issue in the optimal placement of the slit is the distance from the CCD detector at which it is going to be placed. The frequency of the diffraction patter depends on the distance $d$; it is larger for smaller $d$, and smaller for larger $d$. In the limit $\frac{a^2}{d\lambda} \ll 1$ the diffraction pattern of a point source is recovered (Fraunhofer diffraction in the far field).

This dependence on the distance was also tested experimentally and the results are shown in \refFig{slit_scheme}.
The signal in one pixel is the average over all oscillations, that fit into the width of the pixel. Therefore the optimal slit position is close to the chip, since then the frequencies are maximal.

\pltCustom{
	\begin{overpic}[width=0.5\textwidth]{drafts/slit_scheme.pdf}
		\put (1,67) {\textbf{a.}}
	\end{overpic}
	\input{plots/slit_dist.pgf}
	\begin{textblock}{2}(6,-2.955)
		\textbf{b.}
	\end{textblock}
	%\vspace{-2.1em}
}{slit_scheme}{Distance dependent diffraction}{
\textbf{a.}\, A slit was placed on a movable platform and diffraction was measured for various offsets $z$, while the slit opening $a$ was kept constant. \textbf{b.}\, The diffraction frequency rises as the distance gets closer to the CCD.}
