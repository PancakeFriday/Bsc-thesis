\chapter{Setup for high resolution imaging}

\section{Experimental requirements}

\subsection{Experimental setup}
	The atoms in our trap are confined in a vacuum chamber, which has windows in x,y and z direction for the incident lasers, to either trap or image the atoms in the centre. The double species camera (Andor iKon M) is placed along the z axis, above the chamber on a breadboard, where it is also possible to switch to another camera.
	
	A bikonvex lens focuses the imaging beam onto the CCD camera. To minimize the incident background light, the imaging path is covered in SM3 tubes, which can be directly connected to the camera due to a custom made front panel (see Appendix image). \todo{Appendix image}
	\todo{cite carmen}
	
	The camera is also very sensitive to stray light, so that it has to be protected between measurements with a shutter, that covers the front end of the imaging path, such that no light will enter the camera, which will be covered in more detail in \refSec{shutter}
	
	\draft{imaging_path}{Imaging path}{The camera stands on a breadboard, together with the mirrors, the lens and the SM3 tube. The imaging beam originates from the z-axis (pointing out of the document), then transversing as shown.}

\subsection{Basics of CCD cameras}
\label{ch:ccd_basics}
	
	Cameras operate by means of converting photons first into electrons then into voltage and finally read out as data. Each conversion process can add noise to the final image, which needs to be minimized in order to acquire accurate data, which will be covered in \refCh{camera}.
	
	The photons are collected on an array of semiconductors, called the pixels, where ideally the spacing between the pixels is zero to get maximum accuracy. The resolution is then dependent on the pixel size, which is for scientific cameras usually between \SI{10}{\micro\meter} and \SI{20}{\micro\meter} per pixel. Bigger pixels means higher photon sensitivity but usually lower resolution.
	
	To create the digital image, the pixels have to be shifted into the analog digital converter (ADC). This is done, by vertically shifting them into the readout register and then horizontal into the ADC, where the charges are multiplied and converted to digital data.
	
	\draft{ccd_shifts}{CCD scheme}{
		The pixels are arranged in the pixel array. During readout they are shifted upwards into the readout register and then to the side into the analog to digital converter
	}
	
	The shifting is done by storing the charges after collecting them. Each storage can be seen as an electronic potential. To successfully shift the charges and prevent overlapping, three potentials $U_1$, $U_2$ and $U_3$ are necessary. \refFig{charge_shift} indicates the systematics behind the shifting.
	
	\draft{charge_shift}{Shifting charges}{
		To shift charges from Pixel A to Pixel B, the potentials have to be set accordingly to allow the charge flow without overlapping each other. The drawing illustrates the charges moving from Pixel A to B, each row indicates the next step. Moving electrons to the next potential is a three-step process. The charges are first only present in the low potential $U_i$, while $U_{i+1}$ is kept high, then distributed across $U_i$ and $U_{i+1}$ by setting them both low and at last $U_i$ will be set high such that the charge is now fully in $U_{i+1}$.
	}
	
\subsection{Atom imaging} \todo{better title}
	\todo{not sure if it makes sense to write about this chapter}

\section{Camera for double species imaging}
\label{ch:camera}

\subsection{Comparison with the present setup}
For the application of imaging small atom clouds, it is very important to have cameras with optimal noise reduction and maximal readout speed. The new setup improves on both attributes, with the ability to cool the chip down to reduce the dark noise as well as the fast kinetics mode, making it possible to acquire all images before reading out, improving the speed at which images can be taken significantly.

The old setup used a Guppy-38B camera, which is a lot smaller than the Andor~iKon~M \todo{add reference to Marc Repp} (\SI{48.2x30x30}{\milli\meter} vs \SI{204.2x105x107}{\milli\meter}), therefore making an implementation on a full experimental table easier. To implement such a complicated camera system that the Andor is, a lot of preparation was made in the thesis of Carmen. \todo{reference carmen}

Nevertheless, despite its size, the new camera offers the ability to image both Lithium and Caesium species at once, while two Guppy cameras were needed beforehand, which also meant placing them on different imaging axes.

When comparing the resolution, the chip size also has to be considered. Since higher resolutions seem to be preferable at first, it also means that for the same pixel sizes, the photon sensitivities will decrease. The pixel sizes compare to \SI{11}{\micro\meter} to \SI{13}{\micro\meter} from the old versus the new setup respectively, while the resolutions are \SI{768x492}{} and \SI{1024x1024}{} making a larger magnification now possible.
\todo{would be great to have maybe an image of the atoms with the old and new setup (maybe same cooling steps etc.)}

As already mentioned, the readout speed is highly important in our setup. Since absorption imaging is the technique of choice to measure atom attributes, three images need to be taken each sequence, being the absorption, division and background image.
For the Guppy camera, at a frame rate of 30fps, this meant the acquisition was finished after \SI{100}{\milli\second}. The Andor camera, on the other hand, can take images quickly without the need to read out in-between. At the fastest shift speed, the acquisition is finished after \SI{1.2}{\milli\second}, improving the speed by a factor of almost $100$.

\subsection{Dark current}
\begin{itemize}
	\item Theory on Dark current
	\item Temperature dependent
	\item Logarithmic dependency
	\item Water cooling
\end{itemize}
\plt[true]{electrpp}{Dark noise}{
	The dark noise follows a power law dependency. Since these measurements were taken without water cooling installed, deviations are visible as the temperature reaches \SI{-70}{\degreeCelsius}. The convergence to zero on the counts and their variance indicates accurate imaging when low temperatures are used. Gain in this measurement was minimal and the exposure time set to \SI{100}{\second}, such that dark current was the dominant noise source.
}

\newpage
\subsection{Readout noise}
\begin{itemize}
	\item How does pixel shifting work? %http://www.mssl.ucl.ac.uk/www_detector/ccdgroup/optheory/ccdoperation.html
\end{itemize}
As seen in \refCh{ccd_basics}, pixels get shifted in order to be read out. Moving charges from pixel to pixel causes noise to accumulate over each iteration. In theory, this is visible as a gradient since each shift adds new charges due to excitations in the semiconductors. A possible characterization of this effect is to simply take the variance of an image.

Although the shifting gradient is not visible in the final picture, since it is removed by subtracting the background image, it is still important to minimize the noise originating from shifting the charges, which was found to be the case for slow readout speeds, see \refFig{hvspeed}.

\plt{hvspeed}{Readout noise}{
	The pixels are shifted row-wise into the readout register, depending on the vertical shift speed ($v_{ss}$) and then moved pixel-by-pixel with the horizontal shift speed into the analog to digital converter. Since noise reduction is important, minimal horizontal shift speeds will be used, while the vertical shift speed does not seem to affect the variance. To make the readout the dominant noise source, temperature was set to \SI{-69}{\degreeCelsius} and exposure to \SI{10}{\milli\second}.
}
\todo{Add reference}

This is intuitive, since shifting charges means increasing and decreasing potential wells, so that they can move from one into the other. If this is done fast enough, electrons are more likely to excite others from the valence to the conduction band, therefore adding noise.

\newpage
\subsection{Quantum efficiency}
\begin{itemize}
	\item Little bit of theory
	\item Reference to Carmens' thesis
\end{itemize}

\subsection{Pixel correlations}
\begin{itemize}
	\item Mainly the measurement (TBD)
	\item Some example images here maybe?
\end{itemize}

\label{sec:shutter}
\section{Mechanical shutter}

\subsection{Electronic setup}
\begin{itemize}
	\item A simplified circuit
	\item Explanation of the parts
\end{itemize}
\pltCustom{
	\begin{center}
		\includegraphics[width=1\textwidth]{drafts/shutter_circuit_simplified.png}
	\end{center}
}{shutter_circuit_simplified}{}{}

\newpage
\subsection{Dynamical properties}
\plt{shutterDiodeSignal}{
	Shutter characterization}{The dynamics of the shutter were measured using a laser with a variable horizontal offset, which is fixed in this plot, and a photo diode measuring the laser intensity. For various offsets, error functions were fitted yielding the time until the shutter opens to this offset.
}
\todo{appendix image}
\plt{shutterOpen}{Sample dynamics}{
	Opening velocity was measured using the beam diameter and the time the shutter needed to transverse it. It is noticable, that the opening velocity on the right side is faster at first than on the left side. This is due to the structure of the shutter, as can be seen in [Appendix image of shutter].
	The overall opening speed on the other hand is not affected by this and seems to be linear with the offset.
}

\newpage
\section{Mask for the CCD sensor}
\subsection{Fast kinetics mode}
\label{ch:fast_kin}
%\begin{itemize}
%	\item Why it is good
%	\item Shifting timescales
%\end{itemize}
The experiment needs to image both Lithium and Caesium back to back as fast as possible, so that the system does not change significantly during the acquisition of both species.

As explained earlier in \refCh{ccd_basics}, the readout consists of first shifting a row into the readout register and then horizontally shifting them into the ADC. This is a very time consuming process, since the total readout time is described by
\begin{equation}
t_{ij} = i*vspeed + (i-1)*j_{max}*hspeed+j*hspeed
\end{equation}
This equation describes a readout process until a pixel with the coordinates $i$ and $j$, where readout of all pixels beforehand is also taken into account, hence the $j_{max}$ which is the width of the chip in pixels.
As can be seen, for the terms of the horizontal speed, the pixel position has for the last pixel in a row a quadratic dependency, being the dominant terms for the readout, which is necessary to shift the pixels into the ADC.

Therefore, the fast kinetics mode allows the image acquisition to be only dependant on the vertical shift speed, reducing the acquisition time significantly. Only a portion of the CCD is illuminated, while the dark parts of the chip will be used as a storage. This means, that as soon as an image is taken, the illuminated pixels are shifted vertically behind a mask, such that no photons can reach them any more. When the chip is then full or the user has finished their acquisition, the known readout process is then started, including the shift into the ADC, at which point the speed should not matter too much any more, because the experiment is then finished.

\pltCustom{
	\begin{center}
		\begin{overpic}[width=0.5\textwidth]{drafts/fast_kinetics.pdf}
			\put (-6,92) {\textbf{a.}}
			\put (41,92) {\textbf{b.}}
			\put (58,92) {\textbf{c.}}
			\put (5,44) {\textbf{d.}}
			\put (27,44) {\textbf{e.}}
			\put (49,44) {\textbf{f.}}
			\put (69,44) {\textbf{g.}}
		\end{overpic}
	\end{center}
}{fast_kinetics}{Schematics of fast kinetics mode}{
\textbf{a.}\enskip Laser photons excite electrons in the pixel, creating the first absorption image.
\textbf{b.}\enskip The illuminated pixels are shifted down behind the cover of the slit, while the laser is shut off.
\textbf{c.}\enskip The second absorption image is taken without affecting the last measurement.
\textbf{d.}\enskip Both images are shifted down before starting the readout process, to not falsify the data with stray light.
\textbf{e.}\enskip The readout process starts, the first row is shifted into the readout register.
\textbf{f.}\enskip The first pixels are shifted into the ADC.
\textbf{g.}\enskip Step e. to f. are repeated until the chip is cleared.
}

To set up the fast kinetics mode, there are several parameters that need to be set in advance.
\begin{itemize}
	\item \textbf{Series length}\, The number of images acquired before the readout phase is initiated.
	\item \textbf{Exposed rows}\, The height of an image in the fast kinetic series.
	\item \textbf{Offset from bottom}\, Number of rows below each image which is not read out due to diffraction effects of the masking setup which have to be discarded anyway, see \refSubsec{slit}.
\end{itemize}

It can be already seen, that the parameters are limited by the height of the CCD in pixels:
%The CCD has a pixel height of \SI{1024}{\px}, such that the condition
\begin{equation}
\mathbf{Series\,length} * (\mathbf{Exposed\,rows} + \mathbf{Offset\,from\,bottom}) \leq \SI{1024}{px}
\end{equation}
We find it optimal for our application, to expose \SI{200}{\px}, therefore giving a series length of $5$ and an offset of \todo{offset?}. This is since we will be imaging two species, therefore taking an absorption image for each species, followed by two division images, one for each species. The fifth image is left empty, since it would be illuminated during readout, therefore falsifying the data as stated in \refFig{fast_kinetics}. As a matter of fact, the fifth image is cropped out, so that it even the readout time.

\subsection{Frequency response of a slit}
\label{subsec:slit}

In the previous section, the fast kinetics mode was introduced as well as the experimental setup required. The slit in front of the camera is yet another optical element in the path, which will introduce diffraction on the chip - an effect due to the wave nature of light.
\refFig{slit_sketch} is a sketch of the systematics behind a laser wave approaching a slit.

\draft{slit_sketch}{Diffraction on a single slit}{A planar wave with the wavelength $\lambda$ approaches the slit having a width $a$, where the maxima of the wave are drawn as dashed lines. After the slit, Huygens principle is sketched as spherical waves, in purple and green, interfering with each other, which is described in more detail below. The new wavefront is therefore where the 	waves cross each other and is as such visible on the screen to the right.}

The incoming planar wave can be described by the formula:
\begin{equation}
E(x,z) = E_0 e^{-ikz},
\end{equation}
where the wave is propagating in the $z$-Direction with the wave number $k$ and an amplitude $E_0$.

It is known from Huygens principle, that each point from a planar wave can be seen as the origin of a spherical wave. The spherical waves will interfere with each other, making use of the superposition principle and therefore building up the new wavefront.

\todo{reference d. steck}
The mathematical formalism of Huygens principle is simply the sum of all spherical waves, which is for infinitely small distances given as:
\begin{equation}
E(x,z) = E_0 C \int_{Slit} \frac{1}{r^2} \mathrm{exp}(-ikr)\mathrm{d}x'.
\end{equation}
Here, $r=\sqrt{(x-x')^2 + z^2}$ is the radius of a two dimensional wave, C is a normalization constant.
Taylor expansion allows us, to substitute $r^2$ with $z^2$ and $r$ with $\frac{(x-x')^2}{2z} + z^2$, while also the approximation $(x-x') \ll z$ needs to be fulfilled. Therefore we get:
\begin{equation}
E(x,z) = E_0 e^{-ikz}\sqrt{\frac{ik}{2\pi z}}\int_{Slit} \mathrm{exp}(-\frac{ik}{2z}(x-x')^2)\mathrm{d}x'.
\end{equation}
The normalization was derived from the gaussian normal distribution. The integral will run over the slit size, with the origin in its middle, the width being $a$.
We want to also write the exponential as a function of $-\frac{i\pi t^2}{2}$, due to the definition of fresnel integrals. The substitution follows:
\begin{equation}
\frac{k}{2z}(x-x')^2 = \frac{\pi t^2}{2},
\end{equation}
\begin{equation}
\Rightarrow t = \sqrt{\frac{k}{z\pi}}(x-x'), \\
\end{equation}
\begin{equation}
\Rightarrow \mathrm{d}x' = -\mathrm{d}t \sqrt{\frac{z\pi}{k}},
\end{equation}
such that the field becomes
\begin{equation}
E(x,z) = -E_0 e^{-ikz}\sqrt{\frac{i}{2}}\int_{t(-a/2)}^{t(a/2)} \mathrm{exp}(-\frac{i\pi t^2}{2})\mathrm{d}t.
\end{equation}
The fresnel integrals are defined by
\begin{equation}
C(x) = \int_0^x \mathrm{cos}(\frac{\pi t^2}{2})\mathrm{d}t,
\end{equation}
\begin{equation}
S(x) = \int_0^x \mathrm{sin}(\frac{\pi t^2}{2})\mathrm{d}t,
\end{equation}

so that in combination with Eulers equations and splitting up the integrals the equation for the electric field is:
\begin{equation}
E(x,z) = E_0 \sqrt{\frac{i}{2}} e^{-ikz} \left [ C(-a/2) - C(a/2) - iS(-a/2) + iS(a/2) \right ].
\end{equation}

In a real experiment, the light would fall on a CCD chip with its electric field $E(x,z)$, while the representation would later be the intensity, which is given by
\begin{equation}
I(x,z) = \frac{2 \lvert E(x,z) \rvert ^2}{\epsilon_0 c} ,
\end{equation}
with the dielectric constant $\epsilon_0$ and the speed of light $c$.

To verify the theory, we set up a simple experiment with a collimated laser beam pointing at the CCD of the Andor camera, with a slit in between, the results of which can be seen in \refFig{slit}.

\plt{slit}{Diffraction measurement}{
	In order to characterize the diffraction on the CCD, a slit was placed as close as possible. The parameters were then measured as distance $d=\SI{10.9}{\milli\meter}$, opening $a=\SI{2.5}{\milli\meter}$ using a ruler, therefore limiting the accuracy to \SI{0.5}{\milli\meter}. The wavelength was $\lambda =\SI{852}{\nano\meter}$ found from the laser specifications. The blue curve is the experimental data, while the red curve was fitted, leaving distance and opening free. They were found to be $d^\prime=\SI{11.0\pm0.3}{\milli\meter}$ and $a^\prime=\SI{2.470\pm0.013}{\milli\meter}$, which is in close agreement. The laser does not have a constant intensity over the chip size, therefore deviations in amplitude are visible.
}

Apparently, the theory matches the experiment very well, since the deviations are in the expected regimes.
The function washes out as it approaches the centre of the chip. This is due to the nature of the pixels, which only have a finite size and the fact, that the frequencies of the oscillations are lower on the outer ends. All oscillations that fit into one pixel are averaged, therefore diffraction is not visible and it can be said that the data is accurate.

A further experiment has been deduced to also find a relation of the frequencies to the slit distance, which can be seen in \refFig{slit_scheme}.

\pltCustom{
	\begin{overpic}[width=0.5\textwidth]{drafts/slit_scheme.pdf}
		\put (1,67) {\textbf{a.}}
	\end{overpic}
	\input{plots/slit_dist.pgf}
	\begin{textblock}{2}(6,-2.955)
		\textbf{b.}
	\end{textblock}
	%\vspace{-2.1em}
}{slit_scheme}{Distance dependent diffraction}{
\textbf{a.}\, A slit was placed on a movable platform and diffraction was measured for various offsets $z$, while the slit opening $a$ was kept constant. \textbf{b.}\, The diffraction frequency rises as the distance gets closer to the CCD.}

The optimal slit position is therefore close to the chip, since at this position the frequencies are maximal, therefore more oscillations fit into one pixel.
\todo{Why slit not in focus in 1:1?}
\newpage
\subsection{Optimization of the masking setup}
\label{subsec:slit_optim}
As already discussed in \refCh{fast_kin}, part of the chip needs to be covered in order to take images using the fast kinetics mode. In \refSubsec{slit}, it was then derived, that the slit needs to be as close to the chip as possible. In order to achieve that, we needed to do some modifications on the camera.

\draft{camera}{Drawing of the camera}{As can be seen in this drawing, the CCD chip is first hidden behind a cover, that also includes an internal shutter and then offset by an additional \SI{5}{\milli\meter}.} \todo{also put here technical drawing of the custom plate}

The cover, which can be seen in \refFig{cam_drawing} has a width of \SI{12.5}{\milli\meter}, which adds additional space before the chip. The cover is mainly for a manual cap to cover the chip, when the camera is not used, and an internal shutter. Since we knew, that the internal shutter was not needed, we were able to remove the cover bringing us closer to the chip. Images of under the cover can be found in Appendix \todo{A/B/C? Image?}.

The holes for M4 screws were already there, so a custom plate was built on which the slit could be mounted on.
In the technical drawing in \refFig{cam_drawing}, the centre-most holes are reserved for the slit, which can be moved up and down to select the appropriate height needed for the imaging.
The plate also gives the opportunity to move the whole set with the long holes in the outer-most edges.

It is also important to note, that the camera is very sensitive to stray light. The necessity to cover the laser path is unavoidable, but fortunately a simple solution. The plate offers another set of screw holes, which will hold a SM3-mount, therefore eliminating any gap that could allow photons to reach the camera externally.

The long path of SM3 tubes then only allows the smallest amount of stray light to enter the camera, which will have significantly lower intensity than the actual absorption image.
